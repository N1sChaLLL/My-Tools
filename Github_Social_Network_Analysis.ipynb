{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHub Social Network Analysis with Security Focus\n",
    "## Complete Implementation with Tkinter GUI & Integrated Plotting\n",
    "**Team 21 - 19CSE337 | Complete Glow Up Version**\n",
    "\n",
    "---\n",
    "\n",
    "### Features:\n",
    "- âœ… GitHub API Data Collection\n",
    "- âœ… Network Analysis (7 Centrality Measures)\n",
    "- âœ… Community Detection (4 Algorithms)\n",
    "- âœ… **Sybil Account Detection (Security Focus)**\n",
    "- âœ… Bipartite Network Analysis\n",
    "- âœ… Tkinter GUI with Embedded Matplotlib Plots\n",
    "- âœ… Dynamic Visualizations\n",
    "- âœ… Complete Error Handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GitPython in c:\\python310\\lib\\site-packages (3.1.45)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\python310\\lib\\site-packages (from GitPython) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\python310\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython) (5.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: PyGithub in c:\\python310\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: pynacl>=1.4.0 in c:\\python310\\lib\\site-packages (from PyGithub) (1.6.0)\n",
      "Requirement already satisfied: requests>=2.14.0 in c:\\python310\\lib\\site-packages (from PyGithub) (2.32.4)\n",
      "Requirement already satisfied: pyjwt>=2.4.0 in c:\\python310\\lib\\site-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\python310\\lib\\site-packages (from PyGithub) (4.14.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\python310\\lib\\site-packages (from PyGithub) (2.5.0)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in c:\\python310\\lib\\site-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (44.0.2)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\python310\\lib\\site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.4.0->PyGithub) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.4.0->PyGithub) (2.21)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python310\\lib\\site-packages (from requests>=2.14.0->PyGithub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests>=2.14.0->PyGithub) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests>=2.14.0->PyGithub) (2025.7.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install PyGithub github\n",
    "%pip install GitPython\n",
    "%pip install PyGithub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox, scrolledtext\n",
    "from github import Github, Auth\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import threading\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODULE 1: GITHUB DATA COLLECTOR WITH ERROR HANDLING\n",
    "# ============================================================================\n",
    "\n",
    "from github import Auth, Github\n",
    "import time\n",
    "from github.GithubException import GithubException\n",
    "\n",
    "class GitHubDataCollector:\n",
    "    \"\"\"Collects GitHub network data with robust error handling\"\"\"\n",
    "    \n",
    "    def __init__(self, token, callback=None):\n",
    "        self.token = token\n",
    "        self.callback = callback\n",
    "        try:\n",
    "            self.client = Github(auth=Auth.Token(token), per_page=100)\n",
    "            # Test connection lazily\n",
    "            _ = self.client.get_user().login\n",
    "            self.connected = True\n",
    "        except Exception:\n",
    "            self.connected = False\n",
    "    \n",
    "    def log(self, msg):\n",
    "        if self.callback:\n",
    "            try:\n",
    "                self.callback(msg)\n",
    "            except Exception:\n",
    "                pass\n",
    "    \n",
    "    def collect_user_network(self, username, depth=2, max_nodes=500):\n",
    "        \"\"\"Collect user follower network\"\"\"\n",
    "        if not self.connected:\n",
    "            self.log(\"âŒ Not connected to GitHub\")\n",
    "            return {'users': [], 'edges': []}\n",
    "        \n",
    "        users = set()\n",
    "        edges = []\n",
    "        queue = [username]\n",
    "        visited = set()\n",
    "        \n",
    "        try:\n",
    "            for level in range(depth):\n",
    "                next_queue = []\n",
    "                for user_id in queue:\n",
    "                    if len(users) >= max_nodes or user_id in visited:\n",
    "                        continue\n",
    "                    visited.add(user_id)\n",
    "                    users.add(user_id)\n",
    "                    \n",
    "                    try:\n",
    "                        # Check rate limit\n",
    "                        rate_limit = self.client.get_rate_limit()\n",
    "                        if getattr(rate_limit, 'core', None) and rate_limit.core.remaining < 10:\n",
    "                            self.log(f\"âš  Rate limit low: {rate_limit.core.remaining}\")\n",
    "                            break\n",
    "                        \n",
    "                        user = self.client.get_user(user_id)\n",
    "                        followers = list(user.get_followers())[:50]\n",
    "                        \n",
    "                        for follower in followers:\n",
    "                            if len(users) < max_nodes:\n",
    "                                users.add(follower.login)\n",
    "                                edges.append((follower.login, user_id))\n",
    "                                next_queue.append(follower.login)\n",
    "                        \n",
    "                        self.log(f\"âœ“ {user_id}: {len(followers)} followers\")\n",
    "                        time.sleep(0.3)\n",
    "                    \n",
    "                    except GithubException as e:\n",
    "                        if \"404\" in str(e):\n",
    "                            self.log(f\"âš  User '{user_id}' not found (private/deleted)\")\n",
    "                        else:\n",
    "                            self.log(f\"âš  Error: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                queue = next_queue[:max_nodes - len(users)]\n",
    "        except Exception as e:\n",
    "            self.log(f\"âŒ Collection error: {e}\")\n",
    "        \n",
    "        self.log(f\"âœ… Collected {len(users)} users, {len(edges)} connections\")\n",
    "        return {'users': list(users), 'edges': edges}\n",
    "    \n",
    "    def collect_repo_network(self, repo_name, max_nodes=500):\n",
    "        \"\"\"Collect repository stargazer network\"\"\"\n",
    "        if not self.connected:\n",
    "            return {'repos': [], 'edges': []}\n",
    "        \n",
    "        repos = set()\n",
    "        edges = []\n",
    "        \n",
    "        try:\n",
    "            repo = self.client.get_repo(repo_name)\n",
    "            repos.add(repo_name)\n",
    "            \n",
    "            stargazers = list(repo.get_stargazers())[:min(100, max_nodes)]\n",
    "            \n",
    "            for star in stargazers:\n",
    "                repos.add(star.login)\n",
    "                edges.append((star.login, repo_name))\n",
    "            \n",
    "            self.log(f\"âœ… Collected {len(repos)} repos, {len(edges)} interactions\")\n",
    "        \n",
    "        except GithubException as e:\n",
    "            if \"404\" in str(e):\n",
    "                self.log(f\"âŒ Repository '{repo_name}' not found\")\n",
    "            else:\n",
    "                self.log(f\"âŒ Error: {e}\")\n",
    "        \n",
    "        return {'repos': list(repos), 'edges': edges}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All packages installed!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\n",
    "    'PyGithub>=2.1.0',\n",
    "    'networkx>=3.1',\n",
    "    'matplotlib>=3.7.0',\n",
    "    'numpy>=1.24.0',\n",
    "    'pandas>=2.0.0',\n",
    "    'scipy>=1.11.0',\n",
    "    'plotly>=5.0.0',\n",
    "    'kaleido',\n",
    "    'Pillow'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
    "\n",
    "print(\"âœ… All packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT ALL REQUIRED LIBRARIES\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "from github import Github, GithubException, RateLimitExceededException\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.figure import Figure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import threading\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Try to load .env automatically if python-dotenv is available\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "    # Github follower network collection (fixed indentation and placement)\n",
    "    def collect_follower_network(self, user_id, depth=2, max_nodes=500):\n",
    "        \"\"\"Collect follower network for a user up to a certain depth\"\"\"\n",
    "        if not self.connected:\n",
    "            return {'users': [], 'edges': []}\n",
    "\n",
    "        users = set()\n",
    "        edges = []\n",
    "        visited = set()\n",
    "        queue = [user_id]\n",
    "\n",
    "        try:\n",
    "            for level in range(depth):\n",
    "                next_queue = []\n",
    "                for user_id in queue:\n",
    "                    if len(users) >= max_nodes or user_id in visited:\n",
    "                        continue\n",
    "                    visited.add(user_id)\n",
    "                    users.add(user_id)\n",
    "\n",
    "                    try:\n",
    "                        # Check rate limit\n",
    "                        rate_limit = self.client.get_rate_limit()\n",
    "                        if rate_limit.core.remaining < 10:\n",
    "                            self.log(f\"âš  Rate limit low: {rate_limit.core.remaining}\")\n",
    "                            break\n",
    "\n",
    "                        user = self.client.get_user(user_id)\n",
    "                        followers = list(user.get_followers())[:50]\n",
    "\n",
    "                        for follower in followers:\n",
    "                            if len(users) < max_nodes:\n",
    "                                users.add(follower.login)\n",
    "                                edges.append((follower.login, user_id))\n",
    "                                next_queue.append(follower.login)\n",
    "\n",
    "                        self.log(f\"âœ“ {user_id}: {len(followers)} followers\")\n",
    "                        time.sleep(0.3)\n",
    "\n",
    "                    except GithubException as e:\n",
    "                        if \"404\" in str(e):\n",
    "                            self.log(f\"âš  User '{user_id}' not found (private/deleted)\")\n",
    "                        else:\n",
    "                            self.log(f\"âš  Error: {e}\")\n",
    "                        continue\n",
    "\n",
    "                queue = next_queue[:max_nodes - len(users)]\n",
    "\n",
    "        except Exception as e:\n",
    "            self.log(f\"âŒ Collection error: {e}\")\n",
    "\n",
    "        self.log(f\"âœ… Collected {len(users)} users, {len(edges)} connections\")\n",
    "        return {'users': list(users), 'edges': edges}\n",
    "    \n",
    "    def collect_repo_network(self, repo_name, max_nodes=500):\n",
    "        \"\"\"Collect repository stargazer network\"\"\"\n",
    "        if not self.connected:\n",
    "            return {'repos': [], 'edges': []}\n",
    "        \n",
    "        repos = set()\n",
    "        edges = []\n",
    "        \n",
    "        try:\n",
    "            repo = self.client.get_repo(repo_name)\n",
    "            repos.add(repo_name)\n",
    "            \n",
    "            stargazers = list(repo.get_stargazers())[:min(100, max_nodes)]\n",
    "            \n",
    "            for star in stargazers:\n",
    "                repos.add(star.login)\n",
    "                edges.append((star.login, repo_name))\n",
    "            \n",
    "            self.log(f\"âœ… Collected {len(repos)} repos, {len(edges)} interactions\")\n",
    "        \n",
    "        except GithubException as e:\n",
    "            if \"404\" in str(e):\n",
    "                self.log(f\"âŒ Repository '{repo_name}' not found\")\n",
    "            else:\n",
    "                self.log(f\"âŒ Error: {e}\")\n",
    "        \n",
    "        return {'repos': list(repos), 'edges': edges}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODULE 2: NETWORK BUILDER\n",
    "# ============================================================================\n",
    "\n",
    "class NetworkBuilder:\n",
    "    \"\"\"Builds NetworkX graphs from collected data\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_network(data, network_type='user'):\n",
    "        G = nx.DiGraph()\n",
    "        nodes = data.get('users', []) or data.get('repos', [])\n",
    "        G.add_nodes_from(nodes)\n",
    "        G.add_edges_from(data.get('edges', []))\n",
    "        return G\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODULE 3: CENTRALITY CALCULATOR (7 MEASURES)\n",
    "# ============================================================================\n",
    "\n",
    "class CentralityCalculator:\n",
    "    \"\"\"Calculates 7 different centrality measures\"\"\"\n",
    "    \n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "    \n",
    "    def degree_centrality(self):\n",
    "        return nx.degree_centrality(self.graph)\n",
    "    \n",
    "    def betweenness_centrality(self):\n",
    "        return nx.betweenness_centrality(self.graph)\n",
    "    \n",
    "    def closeness_centrality(self):\n",
    "        try:\n",
    "            return nx.closeness_centrality(self.graph)\n",
    "        except:\n",
    "            return {}\n",
    "    \n",
    "    def pagerank(self):\n",
    "        return nx.pagerank(self.graph)\n",
    "    \n",
    "    def eigenvector_centrality(self):\n",
    "        try:\n",
    "            return nx.eigenvector_centrality(self.graph, max_iter=1000)\n",
    "        except:\n",
    "            return {}\n",
    "    \n",
    "    def katz_centrality(self, alpha=0.1):\n",
    "        try:\n",
    "            return nx.katz_centrality(self.graph, alpha=alpha)\n",
    "        except:\n",
    "            return {}\n",
    "    \n",
    "    def get_all_centralities(self):\n",
    "        \"\"\"Get all 7 centrality measures\"\"\"\n",
    "        return {\n",
    "            'Degree': self.degree_centrality(),\n",
    "            'Betweenness': self.betweenness_centrality(),\n",
    "            'Closeness': self.closeness_centrality(),\n",
    "            'PageRank': self.pagerank(),\n",
    "            'Eigenvector': self.eigenvector_centrality(),\n",
    "            'Katz': self.katz_centrality()\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommunityDetector:\n",
    "    \"\"\"Enhanced community detection with visualization and analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "        if self.graph.is_directed():\n",
    "            self._ud = self.graph.to_undirected()\n",
    "        else:\n",
    "            self._ud = self.graph\n",
    "    \n",
    "    def louvain(self):\n",
    "        \"\"\"Louvain community detection\"\"\"\n",
    "        try:\n",
    "            from networkx.algorithms import community\n",
    "            communities = list(community.greedy_modularity_communities(self._ud))\n",
    "            return [set(comm) for comm in communities]\n",
    "        except:\n",
    "            return [set(self._ud.nodes())]\n",
    "    \n",
    "    def girvan_newman(self, num_communities=None):\n",
    "        \"\"\"Girvan-Newman edge betweenness community detection\"\"\"\n",
    "        try:\n",
    "            from networkx.algorithms import community\n",
    "            communities = list(community.edge_betweenness_centrality(self._ud))\n",
    "            if num_communities:\n",
    "                communities = communities[:num_communities]\n",
    "            return [set(comm) for comm in communities]\n",
    "        except:\n",
    "            return [set(self._ud.nodes())]\n",
    "    \n",
    "    def label_propagation(self):\n",
    "        \"\"\"Label propagation algorithm\"\"\"\n",
    "        try:\n",
    "            from networkx.algorithms import community\n",
    "            communities = list(community.label_propagation_communities(self._ud))\n",
    "            return [set(comm) for comm in communities]\n",
    "        except:\n",
    "            return [set(self._ud.nodes())]\n",
    "    \n",
    "    def greedy_modularity(self):\n",
    "        \"\"\"Greedy modularity optimization\"\"\"\n",
    "        try:\n",
    "            from networkx.algorithms import community\n",
    "            communities = list(community.greedy_modularity_communities(self._ud))\n",
    "            return [set(comm) for comm in communities]\n",
    "        except:\n",
    "            return [set(self._ud.nodes())]\n",
    "    \n",
    "    def asyn_lpa_communities(self):\n",
    "        \"\"\"Asynchronous label propagation\"\"\"\n",
    "        try:\n",
    "            from networkx.algorithms import community\n",
    "            communities = list(community.asyn_lpa_communities(self._ud))\n",
    "            return [set(comm) for comm in communities]\n",
    "        except:\n",
    "            return [set(self._ud.nodes())]\n",
    "    \n",
    "    def modularity(self, communities):\n",
    "        \"\"\"Calculate modularity of community partition\"\"\"\n",
    "        try:\n",
    "            from networkx.algorithms import community\n",
    "            return community.modularity(self._ud, communities)\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def analyze_communities(self, communities):\n",
    "        \"\"\"Comprehensive community analysis\"\"\"\n",
    "        analysis = {\n",
    "            'num_communities': len(communities),\n",
    "            'modularity': self.modularity(communities),\n",
    "            'community_sizes': sorted([len(c) for c in communities], reverse=True),\n",
    "            'largest_community': max(len(c) for c in communities) if communities else 0,\n",
    "            'smallest_community': min(len(c) for c in communities) if communities else 0,\n",
    "            'communities': communities\n",
    "        }\n",
    "        \n",
    "        # Density of each community\n",
    "        densities = []\n",
    "        for comm in communities:\n",
    "            subgraph = self._ud.subgraph(comm)\n",
    "            if len(subgraph) > 1:\n",
    "                densities.append(nx.density(subgraph))\n",
    "        \n",
    "        analysis['avg_internal_density'] = np.mean(densities) if densities else 0.0\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def visualize_communities(self, communities, figsize=(14, 8)):\n",
    "        \"\"\"Visualize communities with different colors\"\"\"\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        pos = nx.spring_layout(self._ud, k=1/np.sqrt(len(self._ud.nodes())), iterations=50)\n",
    "        \n",
    "        # Create color map\n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(communities)))\n",
    "        node_colors = {}\n",
    "        \n",
    "        for i, comm in enumerate(communities):\n",
    "            for node in comm:\n",
    "                node_colors[node] = colors[i]\n",
    "        \n",
    "        node_color_list = [node_colors.get(node, 'lightgray') for node in self._ud.nodes()]\n",
    "        \n",
    "        nx.draw_networkx_nodes(self._ud, pos, node_color=node_color_list, \n",
    "                              node_size=300, alpha=0.9)\n",
    "        nx.draw_networkx_edges(self._ud, pos, edge_color='gray', alpha=0.3)\n",
    "        nx.draw_networkx_labels(self._ud, pos, font_size=8)\n",
    "        \n",
    "        plt.title('Community Detection Visualization', fontsize=14, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        return fig\n",
    "\n",
    "def detect_communities_improved(self):\n",
    "    \"\"\"Enhanced community detection with multiple algorithms\"\"\"\n",
    "    if self.network is None:\n",
    "        messagebox.showwarning('Warning', 'Please collect data first')\n",
    "        return\n",
    "    \n",
    "    def run_detection():\n",
    "        algo = self.algo_var.get()\n",
    "        self.log(f'ðŸ” Running {algo} community detection...')\n",
    "        \n",
    "        detector = CommunityDetector(self.network)\n",
    "        \n",
    "        if algo == 'Louvain':\n",
    "            communities = detector.louvain()\n",
    "        elif algo == 'Girvan-Newman':\n",
    "            communities = detector.girvan_newman()\n",
    "        elif algo == 'Label Propagation':\n",
    "            communities = detector.label_propagation()\n",
    "        elif algo == 'Async LPA':\n",
    "            communities = detector.asyn_lpa_communities()\n",
    "        else:\n",
    "            communities = detector.greedy_modularity()\n",
    "        \n",
    "        analysis = detector.analyze_communities(communities)\n",
    "        modularity = analysis['modularity']\n",
    "        \n",
    "        # Display results\n",
    "        self.community_text.delete(1.0, tk.END)\n",
    "        output = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘ ðŸ‘¥ COMMUNITY DETECTION ANALYSIS ðŸ‘¥ â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Algorithm: {algo}\n",
    "Number of Communities: {len(communities)}\n",
    "Modularity: {modularity:.4f}\n",
    "Average Internal Density: {analysis['avg_internal_density']:.4f}\n",
    "\n",
    "Community Size Distribution:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\"\"\"\n",
    "        for i, size in enumerate(analysis['community_sizes'][:20], 1):\n",
    "            output += f\"Community {i}: {size} nodes\\n\"\n",
    "        \n",
    "        output += f\"\\n{'â”€'*60}\\nDetailed Community Information:\\n{'â”€'*60}\\n\"\n",
    "        \n",
    "        for i, comm in enumerate(communities[:10], 1):\n",
    "            members = sorted(list(comm))[:15]\n",
    "            output += f\"\\nCommunity {i} ({len(comm)} total members):\\n\"\n",
    "            output += f\"Members: {', '.join(members)}...\\n\"\n",
    "            \n",
    "            # Internal connectivity\n",
    "            subgraph = detector._ud.subgraph(comm)\n",
    "            internal_edges = subgraph.number_of_edges()\n",
    "            output += f\"Internal Edges: {internal_edges}\\n\"\n",
    "        \n",
    "        self.community_text.insert(tk.END, output)\n",
    "        \n",
    "        # Visualize\n",
    "        fig = detector.visualize_communities(communities)\n",
    "        self.embed_plot(fig, self.community_canvas)\n",
    "        \n",
    "        self.log(f'âœ… Found {len(communities)} communities (modularity: {modularity:.4f})')\n",
    "    \n",
    "    threading.Thread(target=run_detection, daemon=True).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODULE 5: SYBIL DETECTOR - HYBRID SECURITY APPROACH (IMPROVED)\n",
    "# ============================================================================\n",
    "\n",
    "class SybilDetector:\n",
    "    \"\"\"Advanced Sybil detector with multiple heuristics and confidence scoring\"\"\"\n",
    "    \n",
    "    def __init__(self, graph, behavioral_weight=0.35, structural_weight=0.35, temporal_weight=0.3):\n",
    "        self.graph = graph\n",
    "        self.behavioral_weight = behavioral_weight\n",
    "        self.structural_weight = structural_weight\n",
    "        self.temporal_weight = temporal_weight\n",
    "        \n",
    "        if self.graph.is_directed():\n",
    "            self._ud = self.graph.to_undirected()\n",
    "        else:\n",
    "            self._ud = self.graph\n",
    "        \n",
    "        # Precompute all metrics\n",
    "        try:\n",
    "            if len(self._ud) > 0:\n",
    "                self.betweenness = nx.betweenness_centrality(self._ud, normalized=True)\n",
    "                self.clustering = nx.clustering(self._ud)\n",
    "                self.avg_neighbor_degree = nx.average_neighbor_degree(self._ud)\n",
    "                self.degree = dict(self._ud.degree())\n",
    "                self.pagerank = nx.pagerank(self._ud)\n",
    "                self.closeness = nx.closeness_centrality(self._ud)\n",
    "                \n",
    "                # Graph metrics\n",
    "                self.density = nx.density(self._ud)\n",
    "                self.avg_clustering = nx.average_clustering(self._ud)\n",
    "                \n",
    "                # Community detection for structural anomalies\n",
    "                try:\n",
    "                    from networkx.algorithms import community\n",
    "                    communities = list(community.greedy_modularity_communities(self._ud))\n",
    "                    self.community_map = {}\n",
    "                    for i, comm in enumerate(communities):\n",
    "                        for node in comm:\n",
    "                            self.community_map[node] = i\n",
    "                except:\n",
    "                    self.community_map = {node: 0 for node in self._ud.nodes()}\n",
    "            else:\n",
    "                self.betweenness = {}\n",
    "                self.clustering = {}\n",
    "                self.avg_neighbor_degree = {}\n",
    "                self.degree = {}\n",
    "                self.pagerank = {}\n",
    "                self.closeness = {}\n",
    "                self.community_map = {}\n",
    "        except Exception:\n",
    "            self.betweenness = {}\n",
    "            self.clustering = {}\n",
    "            self.avg_neighbor_degree = {}\n",
    "            self.degree = {}\n",
    "            self.pagerank = {}\n",
    "            self.closeness = {}\n",
    "            self.community_map = {}\n",
    "        \n",
    "        self._max_degree = max(self.degree.values()) if self.degree else 1\n",
    "        self._max_avg_neighbor = max(self.avg_neighbor_degree.values()) if self.avg_neighbor_degree else 1\n",
    "    \n",
    "    def calculate_behavioral_score(self, node):\n",
    "        \"\"\"Score based on activity patterns (low degree, few connections)\"\"\"\n",
    "        deg = self.degree.get(node, 0)\n",
    "        deg_norm = 1.0 - (deg / (self._max_degree + 1.0))\n",
    "        \n",
    "        avg_nbr = self.avg_neighbor_degree.get(node, 0.0)\n",
    "        nbr_norm = 1.0 - (avg_nbr / (self._max_avg_neighbor + 1.0))\n",
    "        \n",
    "        # Pagerank as indicator of influence\n",
    "        pr = self.pagerank.get(node, 0.0)\n",
    "        pr_norm = 1.0 - min(pr * 1000, 1.0)\n",
    "        \n",
    "        score = 0.5 * deg_norm + 0.3 * nbr_norm + 0.2 * pr_norm\n",
    "        return float(np.clip(score, 0.0, 1.0))\n",
    "    \n",
    "    def calculate_structural_score(self, node):\n",
    "        \"\"\"Score based on network structure (low betweenness, low clustering)\"\"\"\n",
    "        bt = self.betweenness.get(node, 0.0)\n",
    "        cl = self.clustering.get(node, 0.0)\n",
    "        \n",
    "        bt_inv = 1.0 - bt\n",
    "        cl_inv = 1.0 - cl\n",
    "        \n",
    "        # Closeness centrality\n",
    "        close = self.closeness.get(node, 0.0)\n",
    "        close_inv = 1.0 - close\n",
    "        \n",
    "        score = 0.5 * bt_inv + 0.35 * cl_inv + 0.15 * close_inv\n",
    "        return float(np.clip(score, 0.0, 1.0))\n",
    "    \n",
    "    def calculate_anomaly_score(self, node):\n",
    "        \"\"\"Score based on community anomalies and degree distribution\"\"\"\n",
    "        deg = self.degree.get(node, 0)\n",
    "        \n",
    "        # Z-score normalization for degree\n",
    "        degrees = list(self.degree.values())\n",
    "        if len(degrees) > 1:\n",
    "            mean_deg = np.mean(degrees)\n",
    "            std_deg = np.std(degrees)\n",
    "            if std_deg > 0:\n",
    "                z_score = abs((deg - mean_deg) / std_deg)\n",
    "                deg_anomaly = min(z_score / 3.0, 1.0)\n",
    "            else:\n",
    "                deg_anomaly = 0.0\n",
    "        else:\n",
    "            deg_anomaly = 0.0\n",
    "        \n",
    "        # Community isolation score\n",
    "        node_comm = self.community_map.get(node, 0)\n",
    "        neighbors_in_comm = sum(1 for neighbor in self._ud.neighbors(node) \n",
    "                                if self.community_map.get(neighbor, 0) == node_comm)\n",
    "        if deg > 0:\n",
    "            comm_ratio = 1.0 - (neighbors_in_comm / deg)\n",
    "        else:\n",
    "            comm_ratio = 1.0\n",
    "        \n",
    "        score = 0.6 * deg_anomaly + 0.4 * comm_ratio\n",
    "        return float(np.clip(score, 0.0, 1.0))\n",
    "    \n",
    "    def detect_sybils(self):\n",
    "        \"\"\"Multi-factor Sybil detection with detailed reporting\"\"\"\n",
    "        accounts = {}\n",
    "        \n",
    "        for node in self.graph.nodes():\n",
    "            behavioral = self.calculate_behavioral_score(node)\n",
    "            structural = self.calculate_structural_score(node)\n",
    "            anomaly = self.calculate_anomaly_score(node)\n",
    "            \n",
    "            # Weighted combination\n",
    "            combined = (self.behavioral_weight * behavioral + \n",
    "                       self.structural_weight * structural + \n",
    "                       self.temporal_weight * anomaly)\n",
    "            \n",
    "            trust_score = 100 - (combined * 100)\n",
    "            \n",
    "            # Risk classification\n",
    "            if trust_score < 25:\n",
    "                risk_level = \"ðŸ”´ CRITICAL RISK\"\n",
    "            elif trust_score < 35:\n",
    "                risk_level = \"ðŸ”´ HIGH RISK\"\n",
    "            elif trust_score < 50:\n",
    "                risk_level = \"ðŸŸ¡ SUSPICIOUS\"\n",
    "            elif trust_score < 70:\n",
    "                risk_level = \"ðŸŸ  LOW RISK\"\n",
    "            else:\n",
    "                risk_level = \"ðŸŸ¢ NORMAL\"\n",
    "            \n",
    "            accounts[node] = {\n",
    "                'behavioral': float(behavioral),\n",
    "                'structural': float(structural),\n",
    "                'anomaly': float(anomaly),\n",
    "                'trust_score': float(np.clip(trust_score, 0.0, 100.0)),\n",
    "                'risk_level': risk_level,\n",
    "                'degree': self.degree.get(node, 0),\n",
    "                'clustering': self.clustering.get(node, 0.0),\n",
    "                'betweenness': self.betweenness.get(node, 0.0),\n",
    "                'pagerank': self.pagerank.get(node, 0.0)\n",
    "            }\n",
    "        \n",
    "        # Classification statistics\n",
    "        critical = {k: v for k, v in accounts.items() if v['trust_score'] < 25}\n",
    "        high_risk = {k: v for k, v in accounts.items() if 25 <= v['trust_score'] < 35}\n",
    "        suspicious = {k: v for k, v in accounts.items() if 35 <= v['trust_score'] < 50}\n",
    "        \n",
    "        avg_trust = float(np.mean([v['trust_score'] for v in accounts.values()])) if accounts else 100.0\n",
    "        \n",
    "        return {\n",
    "            'accounts': accounts,\n",
    "            'total_accounts': len(accounts),\n",
    "            'critical_count': len(critical),\n",
    "            'high_risk_count': len(high_risk),\n",
    "            'suspicious_count': len(suspicious),\n",
    "            'avg_trust': avg_trust,\n",
    "            'critical_pct': (len(critical) / max(len(accounts), 1)) * 100,\n",
    "            'high_risk_pct': (len(high_risk) / max(len(accounts), 1)) * 100,\n",
    "            'suspicious_pct': (len(suspicious) / max(len(accounts), 1)) * 100\n",
    "        }\n",
    "    \n",
    "    def flagged_nodes(self, trust_threshold=50.0):\n",
    "        \"\"\"Get flagged nodes below threshold\"\"\"\n",
    "        report = self.detect_sybils()\n",
    "        return sorted([(n, meta['trust_score']) for n, meta in report['accounts'].items() \n",
    "                      if meta['trust_score'] < trust_threshold],\n",
    "                     key=lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODULE 6: VISUALIZER - MATPLOTLIB/NETWORKX PLOTTING (IMPROVED)\n",
    "# ============================================================================\n",
    "\n",
    "class Visualizer:\n",
    "    \"\"\"Network visualization using matplotlib and networkx\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_network(G, title):\n",
    "        \"\"\"Plot network graph with spring layout\"\"\"\n",
    "        fig = plt.figure(figsize=(12, 8))\n",
    "        pos = nx.spring_layout(G, k=1/np.sqrt(len(G.nodes())), iterations=50)\n",
    "        \n",
    "        nx.draw_networkx_nodes(G, pos, node_size=300, node_color='lightblue')\n",
    "        nx.draw_networkx_edges(G, pos, edge_color='gray', alpha=0.5)\n",
    "        nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        return fig\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_centrality(centrality, title):\n",
    "        \"\"\"Plot top nodes by centrality measure\"\"\"\n",
    "        fig = plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Sort by centrality value\n",
    "        sorted_items = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "        nodes, values = zip(*sorted_items)\n",
    "        \n",
    "        plt.bar(nodes, values, color='skyblue')\n",
    "        plt.title(title)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_network_stats(G):\n",
    "        \"\"\"Plot various network statistics\"\"\"\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "        fig.suptitle('Network Statistics Overview', size=16, y=0.95)\n",
    "        \n",
    "        # Get metrics\n",
    "        degree_sequence = [d for n, d in G.degree()]\n",
    "        density = nx.density(G)\n",
    "        avg_clustering = nx.average_clustering(G)\n",
    "        \n",
    "        # 1. Degree Distribution\n",
    "        plt.subplot(221)\n",
    "        plt.hist(degree_sequence, bins=30, color='skyblue', edgecolor='black')\n",
    "        plt.title('Degree Distribution')\n",
    "        plt.xlabel('Degree')\n",
    "        plt.ylabel('Count')\n",
    "        \n",
    "        # 2. Network Metrics\n",
    "        plt.subplot(222)\n",
    "        metrics = {\n",
    "            'Nodes': len(G.nodes()),\n",
    "            'Edges': len(G.edges()),\n",
    "            'Density': density,\n",
    "            'Avg Clustering': avg_clustering\n",
    "        }\n",
    "        plt.bar(metrics.keys(), metrics.values(), color='lightgreen')\n",
    "        plt.title('Network Metrics')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # 3. Degree Centrality Distribution\n",
    "        plt.subplot(223)\n",
    "        centrality = nx.degree_centrality(G)\n",
    "        plt.hist(list(centrality.values()), bins=30, color='lightcoral', edgecolor='black')\n",
    "        plt.title('Degree Centrality Distribution')\n",
    "        plt.xlabel('Centrality')\n",
    "        plt.ylabel('Count')\n",
    "        \n",
    "        # 4. Top Nodes Table\n",
    "        plt.subplot(224)\n",
    "        plt.axis('off')\n",
    "        top_nodes = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        table_data = [[node, f\"{cent:.4f}\"] for node, cent in top_nodes]\n",
    "        plt.table(cellText=table_data,\n",
    "                 colLabels=['Node', 'Centrality'],\n",
    "                 loc='center',\n",
    "                 cellLoc='center',\n",
    "                 colWidths=[0.6, 0.4])\n",
    "        plt.title('Top 10 Nodes by Centrality')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_trust_distribution(accounts):\n",
    "        \"\"\"Plot trust score distribution for Sybil detection\"\"\"\n",
    "        fig = plt.figure(figsize=(10, 4))\n",
    "        \n",
    "        trust_scores = [data['trust_score'] for data in accounts.values()]\n",
    "        \n",
    "        plt.hist(trust_scores, bins=30, color='lightcoral', edgecolor='black')\n",
    "        plt.axvline(x=30, color='red', linestyle='--', label='High Risk Threshold')\n",
    "        plt.axvline(x=50, color='orange', linestyle='--', label='Suspicious Threshold')\n",
    "        \n",
    "        plt.title('Trust Score Distribution')\n",
    "        plt.xlabel('Trust Score')\n",
    "        plt.ylabel('Number of Accounts')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_degree_distribution(G):\n",
    "        \"\"\"Plot degree distribution with fitted power law\"\"\"\n",
    "        fig = plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Get degree sequence\n",
    "        degree_sequence = sorted([d for n, d in G.degree()], reverse=True)\n",
    "        degrees = np.array(list(Counter(degree_sequence).keys()))\n",
    "        frequencies = np.array(list(Counter(degree_sequence).values()))\n",
    "        \n",
    "        # Plot degree distribution\n",
    "        plt.loglog(degrees, frequencies, 'bo-', label='Observed degrees', markersize=8)\n",
    "        \n",
    "        # Fit power law\n",
    "        if len(degrees) > 1:\n",
    "            coefficients = np.polyfit(np.log10(degrees[degrees > 0]), \n",
    "                                   np.log10(frequencies[degrees > 0]), 1)\n",
    "            power_law = 10 ** (coefficients[1] + coefficients[0] * np.log10(degrees))\n",
    "            plt.loglog(degrees, power_law, 'r--', \n",
    "                      label=f'Power law fit (Î³ = {-coefficients[0]:.2f})')\n",
    "        \n",
    "        plt.title('Degree Distribution (Log-Log Scale)')\n",
    "        plt.xlabel('Node Degree (log)')\n",
    "        plt.ylabel('Frequency (log)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_network_metrics(G):\n",
    "        \"\"\"Fixed network metrics that handle both directed and undirected graphs\"\"\"\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "        fig.suptitle('Network Metrics Analysis', size=16, fontweight='bold', y=0.98)\n",
    "\n",
    "        # Convert to undirected for certain metrics\n",
    "        if G.is_directed():\n",
    "            G_undirected = G.to_undirected()\n",
    "        else:\n",
    "            G_undirected = G\n",
    "\n",
    "        # 1. Basic Network Properties\n",
    "        plt.subplot(2, 3, 1)\n",
    "        num_nodes = len(G.nodes())\n",
    "        num_edges = len(G.edges())\n",
    "        density = nx.density(G_undirected)\n",
    "        avg_clustering = nx.average_clustering(G_undirected)\n",
    "\n",
    "        metrics = {\n",
    "            'Nodes': num_nodes,\n",
    "            'Edges': num_edges,\n",
    "            'Density': density,\n",
    "            'Avg\\nClustering': avg_clustering\n",
    "        }\n",
    "\n",
    "        bars = plt.bar(metrics.keys(), metrics.values(), \n",
    "                        color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A'])\n",
    "        plt.title('Basic Network Properties', fontweight='bold')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "        # Add value labels\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "        # 2. Degree Distribution\n",
    "        plt.subplot(2, 3, 2)\n",
    "        if G.is_directed():\n",
    "            degree_seq = [G.degree(n) for n in G.nodes()]\n",
    "        else:\n",
    "            degree_seq = [d for n, d in G.degree()]\n",
    "\n",
    "        plt.hist(degree_seq, bins=min(30, len(set(degree_seq))), \n",
    "                color='#95E1D3', edgecolor='black', alpha=0.7)\n",
    "        plt.title('Degree Distribution', fontweight='bold')\n",
    "        plt.xlabel('Degree')\n",
    "        plt.ylabel('Count')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "        # 3. Clustering Coefficient Distribution\n",
    "        plt.subplot(2, 3, 3)\n",
    "        clustering_coeffs = list(nx.clustering(G_undirected).values())\n",
    "        plt.hist(clustering_coeffs, bins=30, color='#F38181', edgecolor='black', alpha=0.7)\n",
    "        plt.title('Clustering Coefficient Distribution', fontweight='bold')\n",
    "        plt.xlabel('Clustering Coefficient')\n",
    "        plt.ylabel('Count')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "        # 4. Connected Components\n",
    "        plt.subplot(2, 3, 4)\n",
    "        if G.is_directed():\n",
    "            components = list(nx.weakly_connected_components(G))\n",
    "        else:\n",
    "            components = list(nx.connected_components(G))\n",
    "\n",
    "        component_sizes = sorted([len(c) for c in components], reverse=True)[:20]\n",
    "        plt.bar(range(len(component_sizes)), component_sizes, color='#AA96DA')\n",
    "        plt.title(f'Top Connected Components ({len(components)} total)', fontweight='bold')\n",
    "        plt.xlabel('Component Rank')\n",
    "        plt.ylabel('Size')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "        # 5. Degree Centrality\n",
    "        plt.subplot(2, 3, 5)\n",
    "        degree_cent = nx.degree_centrality(G)\n",
    "        top_nodes_cent = sorted(degree_cent.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        nodes_cent, values_cent = zip(*top_nodes_cent)\n",
    "\n",
    "        plt.barh(nodes_cent, values_cent, color='#FCBAD3')\n",
    "        plt.title('Top 10 by Degree Centrality', fontweight='bold')\n",
    "        plt.xlabel('Centrality Score')\n",
    "\n",
    "        # 6. Advanced Metrics Table\n",
    "        plt.subplot(2, 3, 6)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Calculate additional metrics\n",
    "        try:\n",
    "            if G.is_directed():\n",
    "                avg_path = \"N/A (directed)\"\n",
    "            else:\n",
    "                if nx.is_connected(G_undirected):\n",
    "                    avg_path = f\"{nx.average_shortest_path_length(G_undirected):.2f}\"\n",
    "                else:\n",
    "                    avg_path = \"N/A (disconnected)\"\n",
    "        except:\n",
    "            avg_path = \"N/A\"\n",
    "\n",
    "        try:\n",
    "            diameter = f\"{nx.diameter(G_undirected):.0f}\"\n",
    "        except:\n",
    "            diameter = \"N/A\"\n",
    "\n",
    "        try:\n",
    "            transitivity = f\"{nx.transitivity(G_undirected):.4f}\"\n",
    "        except:\n",
    "            transitivity = \"N/A\"\n",
    "\n",
    "        # Create metrics table\n",
    "        metrics_data = [\n",
    "            ['Metric', 'Value'],\n",
    "            ['Total Nodes', f'{num_nodes}'],\n",
    "            ['Total Edges', f'{num_edges}'],\n",
    "            ['Network Density', f'{density:.4f}'],\n",
    "            ['Avg Clustering', f'{avg_clustering:.4f}'],\n",
    "            ['Transitivity', str(transitivity)],\n",
    "            ['Avg Path Length', str(avg_path)],\n",
    "            ['Diameter', str(diameter)],\n",
    "            ['Components', f'{len(components)}']\n",
    "        ]\n",
    "\n",
    "        table = plt.table(cellText=metrics_data, loc='center', cellLoc='left',\n",
    "                            colWidths=[0.5, 0.5])\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(9)\n",
    "        table.scale(1, 2)\n",
    "\n",
    "        # Color header row\n",
    "        for i in range(2):\n",
    "            table[(0, i)].set_facecolor('#95E1D3')\n",
    "            table[(0, i)].set_text_props(weight='bold')\n",
    "\n",
    "        plt.title('Advanced Metrics', fontweight='bold', pad=20)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================\n",
    "# MODULE 7: TKINTER GUI APPLICATION - COMPLETE GLOW UP ðŸŒŸ\n",
    "# ===========================================================================\n",
    "\n",
    "class GitHubSNAApp:\n",
    "    \"\"\"Complete Tkinter GUI Application with Integrated Plotting\"\"\"\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title('ðŸ”’ GitHub SNA Security Platform')\n",
    "        self.root.geometry('1400x900')\n",
    "        self.root.configure(bg='#1e1e1e')\n",
    "        \n",
    "        # Data storage\n",
    "        self.network = None\n",
    "        self.collector = None\n",
    "        self.data = None\n",
    "        self.sybil_results = None\n",
    "        \n",
    "         # Store Tkinter variables as instance variables\n",
    "        self.depth_var = None\n",
    "        self.nodes_var = None\n",
    "        self.algo_var = None\n",
    "        \n",
    "        self.setup_ui()\n",
    "        \n",
    "        # Add cleanup handler\n",
    "        self.root.protocol(\"WM_DELETE_WINDOW\", self.on_closing)\n",
    "    \n",
    "    def on_closing(self):\n",
    "        \"\"\"Clean up Tkinter variables before closing\"\"\"\n",
    "        try:\n",
    "            if self.depth_var:\n",
    "                self.depth_var = None\n",
    "            if self.nodes_var:\n",
    "                self.nodes_var = None\n",
    "            if self.algo_var:\n",
    "                self.algo_var = None\n",
    "            self.root.destroy()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def setup_ui(self):\n",
    "        \"\"\"Setup complete UI with tabs\"\"\"\n",
    "        # Header\n",
    "        header = tk.Label(self.root, text='ðŸ”’ GitHub Social Network Analysis with Security Focus',\n",
    "                          bg='#2e2e2e', fg='#00ff00', font=('Arial', 16, 'bold'), pady=10)\n",
    "        header.pack(fill=tk.X)\n",
    "        \n",
    "        # Main container\n",
    "        main_container = ttk.Frame(self.root)\n",
    "        main_container.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "        \n",
    "        # Create notebook (tabs)\n",
    "        self.notebook = ttk.Notebook(main_container)\n",
    "        self.notebook.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Tab 1: Data Collection\n",
    "        self.setup_collection_tab()\n",
    "        \n",
    "        # Tab 2: Network Analysis\n",
    "        self.setup_analysis_tab()\n",
    "        \n",
    "        # Tab 3: Community Detection\n",
    "        self.setup_community_tab()\n",
    "        \n",
    "        # Tab 4: Sybil Detection (Security)\n",
    "        self.setup_sybil_tab()\n",
    "        \n",
    "        # Tab 5: Statistics\n",
    "        self.setup_stats_tab()\n",
    "    \n",
    "    def setup_collection_tab(self):\n",
    "        \"\"\"Data Collection Tab\"\"\"\n",
    "        frame = ttk.Frame(self.notebook, padding=20)\n",
    "        self.notebook.add(frame, text='ðŸ“¡ Data Collection')\n",
    "        \n",
    "        # Token input\n",
    "        ttk.Label(frame, text='GitHub Token:', font=('Arial', 10, 'bold')).grid(row=0, column=0, sticky=tk.W, pady=5)\n",
    "        self.token_entry = ttk.Entry(frame, width=50, show='*')\n",
    "        self.token_entry.grid(row=0, column=1, padx=10)\n",
    "\n",
    "        # If GITHUB_TOKEN env var exists, indicate and lock the field\n",
    "        env_token = os.environ.get('GITHUB_TOKEN')\n",
    "        if env_token:\n",
    "            self.token_entry.insert(0, 'Using GITHUB_TOKEN from environment (hidden)')\n",
    "            self.token_entry.config(state='disabled')\n",
    "        \n",
    "        # Username (for user-network collection)\n",
    "        ttk.Label(frame, text='GitHub Username (for user network):', font=('Arial', 10, 'bold')).grid(row=1, column=0, sticky=tk.W, pady=5)\n",
    "        self.username_entry = ttk.Entry(frame, width=50)\n",
    "        self.username_entry.grid(row=1, column=1, padx=10)\n",
    "        self.username_entry.insert(0, 'torvalds')\n",
    "        \n",
    "        # Repo owner & name (for repo-network collection)\n",
    "        ttk.Label(frame, text='Repo Owner:', font=('Arial', 10, 'bold')).grid(row=2, column=0, sticky=tk.W, pady=5)\n",
    "        self.owner_entry = ttk.Entry(frame, width=25)\n",
    "        self.owner_entry.grid(row=2, column=1, sticky=tk.W, padx=(10,0))\n",
    "        self.owner_entry.insert(0, 'ahmadawais')\n",
    "\n",
    "        ttk.Label(frame, text='Repo Name:', font=('Arial', 10, 'bold')).grid(row=2, column=1, sticky=tk.W, padx=(180,0))\n",
    "        self.repo_entry = ttk.Entry(frame, width=25)\n",
    "        self.repo_entry.grid(row=2, column=1, sticky=tk.E, padx=(0,10))\n",
    "        self.repo_entry.insert(0, 'hacktoberfest')\n",
    "\n",
    "        # Configuration\n",
    "        ttk.Label(frame, text='Network Depth:', font=('Arial', 10, 'bold')).grid(row=3, column=0, sticky=tk.W, pady=5)\n",
    "        self.depth_var = tk.IntVar(value=2)\n",
    "        ttk.Spinbox(frame, from_=1, to=4, textvariable=self.depth_var, width=10).grid(row=3, column=1, sticky=tk.W, padx=10)\n",
    "        \n",
    "        ttk.Label(frame, text='Max Nodes:', font=('Arial', 10, 'bold')).grid(row=4, column=0, sticky=tk.W, pady=5)\n",
    "        self.nodes_var = tk.IntVar(value=300)\n",
    "        ttk.Spinbox(frame, from_=50, to=2000, textvariable=self.nodes_var, width=10).grid(row=4, column=1, sticky=tk.W, padx=10)\n",
    "        \n",
    "        # Buttons\n",
    "        button_frame = ttk.Frame(frame)\n",
    "        button_frame.grid(row=5, column=0, columnspan=2, pady=20)\n",
    "        \n",
    "        ttk.Button(button_frame, text='ðŸš€ Collect User Network', \n",
    "                  command=self.collect_user_network).pack(side=tk.LEFT, padx=5)\n",
    "        ttk.Button(button_frame, text='ðŸ“¦ Collect Repo Network', \n",
    "                  command=self.collect_repo_network).pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        # Log output\n",
    "        ttk.Label(frame, text='Collection Log:', font=('Arial', 10, 'bold')).grid(row=6, column=0, columnspan=2, sticky=tk.W, pady=10)\n",
    "        \n",
    "        self.log_text = scrolledtext.ScrolledText(frame, height=12, width=80, bg='#2e2e2e', fg='#00ff00', font=('Courier', 9))\n",
    "        self.log_text.grid(row=7, column=0, columnspan=2, pady=10)\n",
    "    \n",
    "    def setup_analysis_tab(self):\n",
    "        \"\"\"Network Analysis Tab with Sub-Tabs\"\"\"\n",
    "        frame = ttk.Frame(self.notebook, padding=20)\n",
    "        self.notebook.add(frame, text='ðŸ•¸ï¸ Network Analysis')\n",
    "        \n",
    "        # Create a nested notebook for analysis sub-tabs\n",
    "        analysis_notebook = ttk.Notebook(frame)\n",
    "        analysis_notebook.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Sub-tab 1: Network Graph\n",
    "        graph_frame = ttk.Frame(analysis_notebook, padding=10)\n",
    "        analysis_notebook.add(graph_frame, text='ðŸ“Š Network Graph')\n",
    "        \n",
    "        ttk.Button(graph_frame, text='Show Network Graph', \n",
    "                  command=self.show_network_graph).pack(side=tk.TOP, pady=10)\n",
    "        self.network_graph_canvas = tk.Canvas(graph_frame, bg='#2e2e2e', height=600)\n",
    "        self.network_graph_canvas.pack(fill=tk.BOTH, expand=True, pady=5)\n",
    "        \n",
    "       # Sub-tab 2 Node Centrality - ALL MEASURES SIMULTANEOUSLY\n",
    "        centralityframe = ttk.Frame(analysis_notebook, padding=10)\n",
    "        analysis_notebook.add(centralityframe, text='Node Centrality')\n",
    "\n",
    "        buttonframe = ttk.Frame(centralityframe)\n",
    "        buttonframe.pack(side=tk.TOP, pady=10)\n",
    "\n",
    "        ttk.Button(buttonframe, text='Show All 7 Centrality Measures', \n",
    "                command=self.show_all_centrality_measures).pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.centralitycanvas = tk.Canvas(centralityframe, bg='#2e2e2e', height=800)\n",
    "        self.centralitycanvas.pack(fill=tk.BOTH, expand=True, pady=5)\n",
    "\n",
    "        \n",
    "        # Sub-tab 3: Degree Distribution\n",
    "        degree_frame = ttk.Frame(analysis_notebook, padding=10)\n",
    "        analysis_notebook.add(degree_frame, text='ðŸ“ˆ Degree Distribution')\n",
    "        \n",
    "        ttk.Button(degree_frame, text='Show Degree Distribution', \n",
    "                  command=self.show_degree_distribution).pack(side=tk.TOP, pady=10)\n",
    "        self.degree_canvas = tk.Canvas(degree_frame, bg='#2e2e2e', height=600)\n",
    "        self.degree_canvas.pack(fill=tk.BOTH, expand=True, pady=5)\n",
    "        \n",
    "        # Sub-tab 4: Network Metrics\n",
    "        metrics_frame = ttk.Frame(analysis_notebook, padding=10)\n",
    "        analysis_notebook.add(metrics_frame, text='ðŸ“Š Network Metrics')\n",
    "        \n",
    "        ttk.Button(metrics_frame, text='Show Network Metrics', \n",
    "                  command=self.show_network_metrics).pack(side=tk.TOP, pady=10)\n",
    "        self.metrics_canvas = tk.Canvas(metrics_frame, bg='#2e2e2e', height=600)\n",
    "        self.metrics_canvas.pack(fill=tk.BOTH, expand=True, pady=5)\n",
    "    \n",
    "    def setup_community_tab(self):\n",
    "        \"\"\"Community Detection Tab\"\"\"\n",
    "        frame = ttk.Frame(self.notebook, padding=20)\n",
    "        self.notebook.add(frame, text='ðŸ‘¥ Communities')\n",
    "        \n",
    "        # Algorithm selection\n",
    "        ttk.Label(frame, text='Algorithm:', font=('Arial', 10, 'bold')).pack(side=tk.LEFT, padx=5)\n",
    "        self.algo_var = tk.StringVar(value='Louvain')\n",
    "        algo_combo = ttk.Combobox(frame, textvariable=self.algo_var,\n",
    "                                 values=['Louvain', 'Girvan-Newman', 'Label Propagation', 'Greedy Modularity'])\n",
    "        algo_combo.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        ttk.Button(frame, text='ðŸ” Detect Communities', \n",
    "                  command=self.detect_communities).pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        # Results\n",
    "        self.community_text = scrolledtext.ScrolledText(frame, height=25, width=100, bg='#2e2e2e', fg='#00ff00', font=('Courier', 9))\n",
    "        self.community_text.pack(fill=tk.BOTH, expand=True, pady=10)\n",
    "    \n",
    "    def setup_sybil_tab(self):\n",
    "        \"\"\"ðŸ”’ Sybil Detection Tab (Security Focus)\"\"\"\n",
    "        frame = ttk.Frame(self.notebook, padding=12)\n",
    "        self.notebook.add(frame, text='ðŸ”’ Sybil Detection')\n",
    "\n",
    "        ttk.Button(frame, text='ðŸ” Detect Sybil Accounts', command=self.detect_sybils).pack(side=tk.TOP, padx=5, pady=8)\n",
    "\n",
    "        # Layout: left -> large canvas for main plot; right -> stats, flagged nodes, thumbnail\n",
    "        content = ttk.Frame(frame)\n",
    "        content.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        left = ttk.Frame(content)\n",
    "        left.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        right = ttk.Frame(content, width=320)\n",
    "        right.pack(side=tk.RIGHT, fill=tk.Y, padx=10)\n",
    "\n",
    "        # Main canvas (large) for detailed plots\n",
    "        self.sybil_canvas = tk.Canvas(left, bg='#2e2e2e', height=400)\n",
    "        self.sybil_canvas.pack(fill=tk.BOTH, expand=True, pady=4)\n",
    "\n",
    "        # Right column: summary labels\n",
    "        stats_label = ttk.Label(right, text='Sybil Summary', font=('Arial', 12, 'bold'))\n",
    "        stats_label.pack(anchor=tk.NW, pady=(6, 4))\n",
    "\n",
    "        self.total_label = ttk.Label(right, text='Total Accounts: -', font=('Arial', 10))\n",
    "        self.total_label.pack(anchor=tk.NW, pady=2)\n",
    "\n",
    "        self.suspicious_label = ttk.Label(right, text='Suspicious: -', font=('Arial', 10))\n",
    "        self.suspicious_label.pack(anchor=tk.NW, pady=2)\n",
    "\n",
    "        self.highrisk_label = ttk.Label(right, text='High Risk: -', font=('Arial', 10))\n",
    "        self.highrisk_label.pack(anchor=tk.NW, pady=2)\n",
    "\n",
    "        # Flagged nodes listbox with scrollbar\n",
    "        ttk.Label(right, text='Flagged Nodes (top 50):', font=('Arial', 10, 'bold')).pack(anchor=tk.NW, pady=(8, 2))\n",
    "        self.flagged_listbox = tk.Listbox(right, height=12, width=40, bg='#1e1e1e', fg='#ff6b6b')\n",
    "        self.flagged_listbox.pack(anchor=tk.NW, fill=tk.X)\n",
    "\n",
    "        # Thumbnail placeholder (Plotly-generated image)\n",
    "        ttk.Label(right, text='Thumbnail:', font=('Arial', 10, 'bold')).pack(anchor=tk.NW, pady=(8, 2))\n",
    "        self.sybil_thumb_label = ttk.Label(right)\n",
    "        self.sybil_thumb_label.pack(anchor=tk.NW, pady=4)\n",
    "\n",
    "        # Results text (detailed) below\n",
    "        self.sybil_text = scrolledtext.ScrolledText(frame, height=6, width=120, bg='#2e2e2e', fg='#ff6b6b', font=('Courier', 9))\n",
    "        self.sybil_text.pack(fill=tk.BOTH, expand=False, pady=8)\n",
    "    \n",
    "    def setup_stats_tab(self):\n",
    "        \"\"\"Statistics Tab\"\"\"\n",
    "        frame = ttk.Frame(self.notebook, padding=20)\n",
    "        self.notebook.add(frame, text='ðŸ“Š Statistics')\n",
    "        \n",
    "        # Canvas for stats\n",
    "        self.stats_canvas = tk.Canvas(frame, bg='#2e2e2e', height=700)\n",
    "        self.stats_canvas.pack(fill=tk.BOTH, expand=True, pady=10)\n",
    "    \n",
    "    def log(self, msg):\n",
    "        \"\"\"Add message to log\"\"\"\n",
    "        timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "        self.log_text.insert(tk.END, f'[{timestamp}] {msg}\\n')\n",
    "        self.log_text.see(tk.END)\n",
    "        self.root.update()\n",
    "    \n",
    "    def collect_user_network(self):\n",
    "        \"\"\"Collect user network\"\"\"\n",
    "        # Prefer environment token\n",
    "        token = os.environ.get('GITHUB_TOKEN') or self.token_entry.get()\n",
    "        username = self.username_entry.get()\n",
    "        depth = self.depth_var.get()\n",
    "        max_nodes = self.nodes_var.get()\n",
    "        \n",
    "        if not token or not username:\n",
    "            messagebox.showerror('Error', 'Please provide token and username (set GITHUB_TOKEN env var or enter token)')\n",
    "            return\n",
    "        \n",
    "        def run_collection():\n",
    "            self.log('ðŸ”„ Starting collection...')\n",
    "            self.collector = GitHubDataCollector(token, self.log)\n",
    "            self.data = self.collector.collect_user_network(username, depth, max_nodes)\n",
    "            self.network = NetworkBuilder.build_network(self.data)\n",
    "            self.log(f'âœ… Network created: {self.network.number_of_nodes()} nodes, {self.network.number_of_edges()} edges')\n",
    "        \n",
    "        threading.Thread(target=run_collection, daemon=True).start()\n",
    "    \n",
    "    def collect_repo_network(self):\n",
    "        \"\"\"Collect repository network\"\"\"\n",
    "        # Prefer environment token\n",
    "        token = os.environ.get('GITHUB_TOKEN') or self.token_entry.get()\n",
    "        owner = self.owner_entry.get().strip()\n",
    "        repo_name = self.repo_entry.get().strip()\n",
    "        \n",
    "        if not token or not owner or not repo_name:\n",
    "            messagebox.showerror('Error', 'Please provide token, repo owner and repo name (set GITHUB_TOKEN env var or enter token)')\n",
    "            return\n",
    "        \n",
    "        repo_full = f\"{owner}/{repo_name}\"\n",
    "        \n",
    "        def run_collection():\n",
    "            self.log(f'ðŸ”„ Starting repo collection for {repo_full}...')\n",
    "            self.collector = GitHubDataCollector(token, self.log)\n",
    "            self.data = self.collector.collect_repo_network(repo_full, self.nodes_var.get())\n",
    "            self.network = NetworkBuilder.build_network(self.data)\n",
    "            self.log(f'âœ… Network created: {self.network.number_of_nodes()} nodes')\n",
    "        \n",
    "        threading.Thread(target=run_collection, daemon=True).start()\n",
    "    \n",
    "    def show_network_graph(self):\n",
    "        \"\"\"Display network graph\"\"\"\n",
    "        if self.network is None:\n",
    "            messagebox.showwarning('Warning', 'Please collect data first')\n",
    "            return\n",
    "        \n",
    "        fig = Visualizer.plot_network(self.network, f'Network Graph ({self.network.number_of_nodes()} nodes)')\n",
    "        self.embed_plot(fig, self.network_graph_canvas)\n",
    "    \n",
    "    def show_all_centrality_measures(self):\n",
    "        \"\"\"Display all 7 centrality measures in a 2x4 grid without dropdown\"\"\"\n",
    "        if self.network is None:\n",
    "            messagebox.showwarning('Warning', 'Please collect data first')\n",
    "            return\n",
    "        \n",
    "        self.log('ðŸ“Š Computing all 7 centrality measures...')\n",
    "        \n",
    "        calc = CentralityCalculator(self.network)\n",
    "        \n",
    "        fig = plt.figure(figsize=(20, 12))\n",
    "        fig.suptitle('All 7 Centrality Measures (Top 10 Nodes)', fontsize=18, fontweight='bold', y=0.98)\n",
    "        \n",
    "        centrality_measures = [\n",
    "            ('Degree', calc.degree_centrality()),\n",
    "            ('Betweenness', calc.betweenness_centrality()),\n",
    "            ('Closeness', calc.closeness_centrality()),\n",
    "            ('PageRank', calc.pagerank()),\n",
    "            ('Eigenvector', calc.eigenvector_centrality()),\n",
    "            ('Katz', calc.katz_centrality()),\n",
    "            ('Harmonic', self.calculate_harmonic_centrality()),\n",
    "        ]\n",
    "        \n",
    "        for idx, (title, centrality) in enumerate(centrality_measures, 1):\n",
    "            if not centrality:\n",
    "                continue\n",
    "            \n",
    "            ax = plt.subplot(2, 4, idx)\n",
    "            \n",
    "            # Get top 10 nodes\n",
    "            sorted_items = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "            if not sorted_items:\n",
    "                continue\n",
    "            \n",
    "            nodes, values = zip(*sorted_items)\n",
    "            \n",
    "            # Color gradient based on values\n",
    "            colors = plt.cm.RdYlGn(np.linspace(0, 1, len(nodes)))\n",
    "            bars = ax.barh(nodes, values, color=colors, edgecolor='black', alpha=0.8)\n",
    "            \n",
    "            ax.set_title(title, fontweight='bold', fontsize=12)\n",
    "            ax.set_xlabel('Score', fontsize=10)\n",
    "            ax.invert_yaxis()\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for i, (bar, val) in enumerate(zip(bars, values)):\n",
    "                ax.text(val, bar.get_y() + bar.get_height()/2, \n",
    "                    f' {val:.4f}', va='center', ha='left', fontsize=8)\n",
    "            \n",
    "            ax.grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        self.embed_plot(fig, self.centralitycanvas)\n",
    "        self.log('âœ… All centrality measures computed successfully')\n",
    "\n",
    "    def calculate_harmonic_centrality(self):\n",
    "        \"\"\"Calculate harmonic centrality\"\"\"\n",
    "        try:\n",
    "            return nx.harmonic_centrality(self.network)\n",
    "        except:\n",
    "            return {}\n",
    "\n",
    "    def showcentrality(self):\n",
    "        \"\"\"Kept for backward compatibility - now calls the all-measures method\"\"\"\n",
    "        self.show_all_centrality_measures()\n",
    "\n",
    "    \n",
    "    def show_degree_distribution(self):\n",
    "        \"\"\"Display degree distribution\"\"\"\n",
    "        if self.network is None:\n",
    "            messagebox.showwarning('Warning', 'Please collect data first')\n",
    "            return\n",
    "        \n",
    "        fig = Visualizer.plot_degree_distribution(self.network)\n",
    "        self.embed_plot(fig, self.degree_canvas)\n",
    "    \n",
    "    def show_network_metrics(self):\n",
    "        \"\"\"Display network metrics\"\"\"\n",
    "        if self.network is None:\n",
    "            messagebox.showwarning('Warning', 'Please collect data first')\n",
    "            return\n",
    "        \n",
    "        fig = Visualizer.plot_network_metrics(self.network)\n",
    "        self.embed_plot(fig, self.metrics_canvas)\n",
    "    \n",
    "    def show_network_stats(self):\n",
    "        \"\"\"Display network statistics\"\"\"\n",
    "        if self.network is None:\n",
    "            messagebox.showwarning('Warning', 'Please collect data first')\n",
    "            return\n",
    "        \n",
    "        fig = Visualizer.plot_network_stats(self.network)\n",
    "        self.embed_plot(fig, self.stats_canvas)\n",
    "    \n",
    "    def detect_communities(self):\n",
    "        \"\"\"Detect communities\"\"\"\n",
    "        if self.network is None:\n",
    "            messagebox.showwarning('Warning', 'Please collect data first')\n",
    "            return\n",
    "        \n",
    "        def run_detection():\n",
    "            algo = self.algo_var.get()\n",
    "            self.log(f'ðŸ” Running {algo} community detection...')\n",
    "            \n",
    "            detector = CommunityDetector(self.network)\n",
    "            \n",
    "            if algo == 'Louvain':\n",
    "                communities = detector.louvain()\n",
    "            elif algo == 'Girvan-Newman':\n",
    "                communities = detector.girvan_newman()\n",
    "            elif algo == 'Label Propagation':\n",
    "                communities = detector.label_propagation()\n",
    "            else:\n",
    "                communities = detector.greedy_modularity()\n",
    "            \n",
    "            modularity = detector.modularity(communities)\n",
    "            \n",
    "            self.community_text.delete(1.0, tk.END)\n",
    "            output = f\"\"\"\n",
    "=== COMMUNITY DETECTION RESULTS ===\n",
    "Algorithm: {algo}\n",
    "Number of Communities: {len(communities)}\n",
    "Modularity: {modularity:.4f}\n",
    "\n",
    "Community Sizes:\n",
    "\"\"\"\n",
    "            for i, comm in enumerate(sorted(communities, key=len, reverse=True)[:20]):\n",
    "                output += f'\\nCommunity {i+1}: {len(comm)} members'\n",
    "                output += f'\\nMembers: {sorted(list(comm))[:10]}...\\n'\n",
    "            \n",
    "            self.community_text.insert(tk.END, output)\n",
    "            self.log(f'âœ… Found {len(communities)} communities (modularity: {modularity:.4f})')\n",
    "        \n",
    "        threading.Thread(target=run_detection, daemon=True).start()\n",
    "    \n",
    "    def detect_sybils(self):\n",
    "        \"\"\"ðŸ”’ Detect Sybil accounts\"\"\"\n",
    "        if self.network is None:\n",
    "            messagebox.showwarning('Warning', 'Please collect data first')\n",
    "            return\n",
    "        \n",
    "        def run_detection():\n",
    "            self.log('ðŸ” Starting Sybil detection...')\n",
    "            detector = SybilDetector(self.network)\n",
    "            self.sybil_results = detector.detect_sybils()\n",
    "            \n",
    "            # Display results\n",
    "            results = self.sybil_results\n",
    "            output = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘         ðŸ”’ SYBIL ACCOUNT DETECTION RESULTS ðŸ”’             â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Total Accounts Analyzed:   {results['total_accounts']}\n",
    "Suspicious Accounts:       {results['suspicious_count']} ({results['suspicious_pct']:.1f}%)\n",
    "High Risk Accounts:        {results['high_risk_count']}\n",
    "Average Trust Score:       {results['avg_trust']:.2f}/100\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "HIGH RISK ACCOUNTS (Trust Score < 30):\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "            \n",
    "            high_risk = {k: v for k, v in results['accounts'].items() if v['trust_score'] < 30}\n",
    "            for i, (account, data) in enumerate(list(sorted(high_risk.items(), key=lambda x: x[1]['trust_score']))):\n",
    "                output += f\"{i+1}. {account}: Trust={data['trust_score']:.1f}/100 {data['risk_level']}\\n\"\n",
    "            \n",
    "            output += \"\\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\"\n",
    "            output += \"SUSPICIOUS ACCOUNTS (Trust Score 30-50):\\n\"\n",
    "            output += \"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\"\n",
    "            \n",
    "            suspicious = {k: v for k, v in results['accounts'].items() if 30 <= v['trust_score'] < 50}\n",
    "            for i, (account, data) in enumerate(list(sorted(suspicious.items(), key=lambda x: x[1]['trust_score']))[:10]):\n",
    "                output += f\"{i+1}. {account}: Trust={data['trust_score']:.1f}/100 {data['risk_level']}\\n\"\n",
    "            \n",
    "            self.sybil_text.delete(1.0, tk.END)\n",
    "            self.sybil_text.insert(tk.END, output)\n",
    "            \n",
    "            # Plot trust distribution\n",
    "            fig = Visualizer.plot_trust_distribution(results['accounts'])\n",
    "            self.embed_plot(fig, self.sybil_canvas)\n",
    "            \n",
    "            self.log('âœ… Sybil detection complete')\n",
    "        \n",
    "        threading.Thread(target=run_detection, daemon=True).start()\n",
    "    \n",
    "    def embed_plot(self, fig, canvas):\n",
    "        \"\"\"Embed matplotlib plot in Tkinter canvas\"\"\"\n",
    "        # Clear canvas\n",
    "        for item in canvas.find_all():\n",
    "            canvas.delete(item)\n",
    "        \n",
    "        # Create plot\n",
    "        plot_canvas = FigureCanvasTkAgg(fig, master=canvas)\n",
    "        plot_canvas.draw()\n",
    "        plot_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running quick synthetic Sybil detector sanity check...\n",
      "Synthetic Sybil Test Results\n",
      "Total: 37\n",
      "Suspicious: 15\n",
      "High risk: 0\n",
      "Flagged (sample): [('user_5', 44.642384472273974), ('user_13', 45.135707622362666), ('user_9', 46.278261574128756), ('user_2', 46.50894610131999), ('user_4', 46.65455638002334), ('user_3', 47.16728684435657), ('user_6', 47.17928280785652), ('user_8', 47.61927345914735), ('user_24', 48.06295040886288), ('user_17', 48.256704810183614)]\n",
      "Planted sybils flagged: 0 / 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Image.__del__ at 0x0000010BCF4CD5A0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python310\\lib\\tkinter\\__init__.py\", line 4046, in __del__\n",
      "    self.tk.call('image', 'delete', self.name)\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Image.__del__ at 0x0000010BCF4CD5A0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python310\\lib\\tkinter\\__init__.py\", line 4046, in __del__\n",
      "    self.tk.call('image', 'delete', self.name)\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Image.__del__ at 0x0000010BCF4CD5A0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python310\\lib\\tkinter\\__init__.py\", line 4046, in __del__\n",
      "    self.tk.call('image', 'delete', self.name)\n",
      "RuntimeError: main thread is not in main loop\n",
      "Exception ignored in: <function Image.__del__ at 0x0000010BCF4CD5A0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python310\\lib\\tkinter\\__init__.py\", line 4046, in __del__\n",
      "    self.tk.call('image', 'delete', self.name)\n",
      "RuntimeError: main thread is not in main loop\n",
      "C:\\Users\\sampa\\AppData\\Local\\Temp\\ipykernel_18080\\1740889227.py:136: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SYNTHETIC TEST: planted sybil-like nodes (not part of GUI) - validation cell\n",
    "# ============================================================================\n",
    "\n",
    "def _synthetic_sybil_test(show_plot=True):\n",
    "    \"\"\"Create a small synthetic graph with a dense core and a cluster of sybil nodes\n",
    "    attached to a single gateway. Run detector and print numeric results.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # dense core\n",
    "    core = nx.erdos_renyi_graph(25, 0.3)\n",
    "    # relabel to string names to mimic GitHub logins\n",
    "    core = nx.relabel_nodes(core, lambda x: f'user_{x}')\n",
    "\n",
    "    # choose a gateway node\n",
    "    gateway = list(core.nodes())[0]\n",
    "\n",
    "    # create sybil cluster: 12 nodes mostly connected to gateway or each other\n",
    "    sybils = [f'sybil_{i}' for i in range(12)]\n",
    "    G = core.copy()\n",
    "    for s in sybils:\n",
    "        G.add_node(s)\n",
    "        # connect to gateway\n",
    "        G.add_edge(s, gateway)\n",
    "        # sparse inter-sybil edges\n",
    "    # add a few random inter-sybil edges\n",
    "    for i in range(len(sybils)):\n",
    "        for j in range(i+1, len(sybils)):\n",
    "            if np.random.rand() < 0.15:\n",
    "                G.add_edge(sybils[i], sybils[j])\n",
    "\n",
    "    # Run detector\n",
    "    detector = SybilDetector(G)\n",
    "    report = detector.detect_sybils()\n",
    "\n",
    "    print('Synthetic Sybil Test Results')\n",
    "    print('Total:', report['total_accounts'])\n",
    "    print('Suspicious:', report['suspicious_count'])\n",
    "    print('High risk:', report['high_risk_count'])\n",
    "    flagged = detector.flagged_nodes(50.0)\n",
    "    print('Flagged (sample):', flagged[:10])\n",
    "\n",
    "    # Basic checks\n",
    "    planted_flagged = [s for s in sybils if s in flagged]\n",
    "    print(f'Planted sybils flagged: {len(planted_flagged)} / {len(sybils)}')\n",
    "\n",
    "    # Show trust distribution plot\n",
    "    if show_plot:\n",
    "        fig = Visualizer.plot_trust_distribution(report['accounts'])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION - RUN THE APPLICATION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        print('\\nRunning quick synthetic Sybil detector sanity check...')\n",
    "        _synthetic_sybil_test(show_plot=False)\n",
    "    except Exception as e:\n",
    "        print('Synthetic test failed:', e)\n",
    "\n",
    "    root = tk.Tk()\n",
    "    app = GitHubSNAApp(root)\n",
    "    try:\n",
    "        root.mainloop()\n",
    "    finally:\n",
    "        # Ensure cleanup happens\n",
    "        app.on_closing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ‰ Complete Implementation Summary\n",
    "\n",
    "## What's Included:\n",
    "\n",
    "### ðŸ“¡ **Data Collection**\n",
    "- GitHub API integration with error handling\n",
    "- User network collection\n",
    "- Repository network collection\n",
    "- Rate limit management\n",
    "\n",
    "### ðŸ•¸ï¸ **Network Analysis**\n",
    "- 7 centrality measures (Degree, Betweenness, Closeness, PageRank, Eigenvector, Katz)\n",
    "- Network statistics and visualization\n",
    "- Graph algorithms\n",
    "\n",
    "### ðŸ‘¥ **Community Detection**\n",
    "- 4 algorithms (Louvain, Girvan-Newman, Label Propagation, Greedy Modularity)\n",
    "- Modularity calculation\n",
    "- Detailed community analysis\n",
    "\n",
    "### ðŸ”’ **Sybil Detection (Security Focus)**\n",
    "- Hybrid behavioral-structural approach\n",
    "- Trust score calculation (0-100)\n",
    "- High-risk account identification\n",
    "- Detailed vulnerability reports\n",
    "\n",
    "### ðŸŽ¨ **Tkinter GUI with Plots**\n",
    "- Professional dark theme\n",
    "- 5 main tabs\n",
    "- Embedded matplotlib visualizations\n",
    "- Real-time logging\n",
    "- Interactive controls\n",
    "\n",
    "### ðŸ“Š **Visualizations**\n",
    "- Network graphs (spring layout)\n",
    "- Centrality distributions\n",
    "- Trust score histograms\n",
    "- Network statistics (4-panel dashboard)\n",
    "- Connected components analysis\n",
    "\n",
    "## How to Use:\n",
    "\n",
    "1. Run all cells in order\n",
    "2. GUI will launch automatically\n",
    "3. Enter GitHub token and username\n",
    "4. Click \"Collect User Network\" or \"Collect Repo Network\"\n",
    "5. Navigate through tabs to view analysis\n",
    "6. Use Sybil Detection tab for security analysis\n",
    "\n",
    "## Example Usage:\n",
    "\n",
    "**Token**: Your GitHub Personal Access Token (from Settings â†’ Developer Settings â†’ Tokens)\n",
    "**Username**: Try \"torvalds\", \"gvanrossum\", \"guido\", or any public GitHub user\n",
    "**Depth**: 1-4 (higher = more followers collected, more API calls)\n",
    "**Max Nodes**: 50-2000 (reasonable range)\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸŽ¯ Complete Glow Up Achieved!** âœ¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
